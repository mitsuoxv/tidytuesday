---
title: "NYTimes best sellers"
date: 2022-05-10
output: html_document
---

# TidyTuesday

Join the R4DS Online Learning Community in the weekly #TidyTuesday event!
Every week we post a raw dataset, a chart or article related to that dataset, and ask you to explore the data.
While the dataset will be “tamed”, it will not always be tidy! As such you might need to apply various R for Data Science techniques to wrangle the data into a true tidy format.
The goal of TidyTuesday is to apply your R skills, get feedback, explore other’s work, and connect with the greater #RStats community!
As such we encourage everyone of all skills to participate!

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(tidytuesdayR)

library(scales)
theme_set(theme_light())

library(ggrepel)
```

# Load the weekly Data

Download the weekly data and make available in two objects.

```{r Load}

nyt_titles <- read_tsv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-05-10/nyt_titles.tsv')
nyt_full <- read_tsv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-05-10/nyt_full.tsv')

```


# Glimpse Data

Take an initial look at the format of the data available.

```{r Glimpse}

list(nyt_titles, nyt_full) %>% 
  map(glimpse)

```

# Wrangle

Explore the data and process it into a nice format for plotting! Access each dataset by name by using a dollarsign after the `tt` object and then the name of the data set.

```{r Wrangle}



```


# Visualize

Using your processed dataset, create your unique visualization.

```{r Visualize}

nyt_titles$year %>% range()

nyt_titles %>% 
  count(year)

nyt_titles %>% 
  mutate(decade = (year %/% 10) * 10) %>% 
  count(decade)

nyt_titles_by_decade <- nyt_titles %>% 
  mutate(
    decade = (year %/% 10) * 10,
    title = str_to_title(title)
    ) %>% 
  add_count(decade)%>% 
  mutate(decade = glue::glue("{decade}s\n({n})"))

p <- nyt_titles_by_decade %>% 
  ggplot(aes(decade, total_weeks)) +
  geom_boxplot() +
  geom_text_repel(aes(label = title), size = 3, 
                  data = nyt_titles_by_decade %>% 
              filter(total_weeks > 150)) +
  scale_y_log10() +
  labs(x = "Decade (first listed in NYT best sellers)",
       y = "Total # of weeks in list\n(log scale)",
       title = "Best sellers' staying weeks got longer from 1930s up to 1970s,\nand have got shorter since then, except some long-lived titles",
       subtitle = "(#) denotes # of titles",
       caption = "Source: Post45 Data")

p
```

# Save Image

Save your image for sharing. Be sure to use the `#TidyTuesday` hashtag in your post on twitter! 

```{r}

# This will save your most recent plot
ggsave("image/nyt_best_sellers.png", p, width = 8, height = 5)

```

# Imitate @leeolney3

Maybe I should learn {gt}.

```{r}
library(gt)
library(gtExtras)
```

```{r}

timeline_by_title <- nyt_full %>% 
  mutate(rank = -rank) %>% 
  group_by(title_id) %>% 
  arrange(week) %>% 
  summarize(timeline = list(rank), .groups = "drop")

nyt_titles %>% 
  slice_max(total_weeks, n = 20) %>% 
  mutate(title = str_to_title(title)) %>% 
  inner_join(timeline_by_title, by = c("id" = "title_id")) %>% 
  select(-id) %>% 
  mutate(wk = total_weeks) %>% 
  relocate(wk, .after = total_weeks) %>% 
  gt() %>% 
  gt_theme_nytimes() %>% 
  gt_sparkline(timeline, label = FALSE) %>% 
  gt_plt_bar_pct(wk) %>% 
  cols_width(
    wk ~ px(100),
    first_week ~ px(100)
    ) %>% 
  cols_align("right", first_week) %>% 
  cols_label(
    total_weeks = "total weeks",
    first_week = "first week",
    debut_rank = "debut rank",
    best_rank = "best rank",
    wk = ""
    ) %>% 
  tab_header(title = "NY Times best sellers",
             subtitle = "List of titles with equal to or more than 80 weeks") %>% 
  tab_source_note("Source: Post45 Data") %>% 
  tab_style(
    style = list(cell_text(style = "italic", color = "black")),
    locations = cells_body(columns = title)
  )

```

# Imitate @tanya_shapiro

https://github.com/tashapiro/TidyTuesday/blob/master/2022/W19/nyt_best_sellers.R
Not yet finished.

```{r}

nyt_full <- nyt_full %>% 
  mutate(
    author = author %>% 
      str_remove("^! by |^\\? by "),
    decade = year - year %% 10,
    title = str_to_title(title)
  ) %>% 
  separate_rows(author, sep = " and ") # co-author

top_titles <- nyt_full %>% 
  count(author, decade, title_id, title,
        name = "weeks") %>% 
  group_by(author, decade) %>% 
  slice_max(weeks, n = 1, with_ties = TRUE) %>% 
  arrange(desc(weeks)) %>% 
  summarize(titles = paste(title, collapse = ", "), .groups = "drop")

decade <- nyt_full %>% 
  group_by(author) %>% 
  mutate(debut_decade = min(decade)) %>% 
  ungroup() %>% 
  group_by(author, decade, debut_decade) %>% 
  summarize(
    weeks = n(),
    books = n_distinct(title_id),
    .groups = "drop"
  ) %>% 
  group_by(decade) %>% 
  mutate(rank = rank(-weeks, ties.method = "first")) %>% 
  left_join(top_titles, by = c("author", "decade")) %>% 
  arrange(decade) %>% 
  group_by(author) %>% 
  mutate(prev_rank = lag(rank)) %>% 
  ungroup() %>% 
  mutate(
    pos = case_when(
      is.na(prev_rank) ~ "Debut",
      rank < prev_rank ~ "Up",
      rank > prev_rank ~ "Down",
      rank == prev_rank ~ "Same"
    ),
    pos = factor(pos, levels = c("Up", "Down", "Same", "Debut"))
  ) %>% 
  filter(decade >= 1970) %>% 
  group_by(decade) %>% 
  slice_max(weeks, n = 10, with_ties = FALSE)

decade %>% 
  ggplot() +
  geom_segment(aes(x = x1, xend = x2, y = y1, yend = y2), color = "gray60",
               data = tibble(x1 = 1.5, x2 = 4.5, y1 = -0.25, y2 = -0.25)) +
  geom_text(aes(label = author, x = 2, y = rank - 0.1), hjust = 0) +
  geom_point(aes(x = 1.8, y = rank + 0.12, shape = pos)) +
  scale_y_reverse() +
  scale_shape_manual(values = c(24, 25, 21, 8),
                     guide = guide_legend(override.aes = list(size = 2))) +
  facet_wrap(vars(paste0(decade, "s"))) +
  labs(shape = "Decade rank shift") +
  theme_void() +
  theme(
    legend.position = "top"
  )

```

# Imitate @TannerFlorian

https://github.com/FCTanner/tidy_tuesday/blob/main/2022/2022-05-10%20NYTimes%20best%20sellers/2022-05-10-NYTimes-best-sellers.md
Not complete.

```{r}
library(ggtext)
```

```{r}

nyt_titles %>% 
  filter(year == 2020) %>% 
  slice_max(total_weeks, n = 10, with_ties = FALSE) %>% 
  mutate(
    title_titlecase = str_to_title(title),
    last_week = first_week + total_weeks * 7,
    rank_that_year = 11 - row_number(),
    best_label = paste0(total_weeks, " weeks: **", title_titlecase, "** by ", author)
  ) %>% 
  ggplot(aes(first_week, rank_that_year, color = rank_that_year)) +
  geom_textbox(aes(label = best_label),
               hjust = 0, vjust = 0, width = unit(3, "inch"),
               box.color = NA,
               box.padding = unit(c(0, 0, 3, 0), "pt"),
               color = "black", size = 3) +
  geom_segment(aes(xend = last_week, yend = rank_that_year)) +
  geom_point() +
  geom_point(aes(last_week)) +
  scale_x_date(date_labels = "%B",
               breaks = as.Date(c("2020-01-01", "2020-03-01", "2020-05-01",
                                  "2020-07-01", "2020-09-01", "2020-11-01",
                                  "2021-01-01"))) +
  guides(color = "none") +
  labs(x = NULL, y = NULL,
       title = "NY Times best sellers in 2020",
       caption = "Source: Post45 Data") +
  theme_minimal() +
  theme(
    axis.text.y = element_blank(),
    panel.grid.major.y = element_blank(),
    panel.grid.minor.y = element_blank()
  )
```

# Imitate Julia Silge

```{r}

glimpse(nyt_titles)

nyt_titles %>% 
  ggplot(aes(total_weeks)) +
  geom_histogram(bins = 40, color = "white")

nyt_titles <- nyt_titles %>% 
  mutate(author = author %>% 
      str_remove("^! by |^\\? by ")) %>% 
  separate_rows(author, sep = " and ") # co-author

nyt_titles %>% 
  group_by(author) %>% 
  summarize(
    n = n(),
    total_weeks = median(total_weeks),
    .groups = "drop_last"
  ) %>% 
  arrange(desc(n))

```

```{r}
library(tidymodels)

nyt_titles %>% 
  select(total_weeks) %>% 
  summary()

set.seed(123)
spl <- nyt_titles %>% 
  transmute(
    author,
    total_weeks = if_else(total_weeks > 4, "long", "short")
  ) %>% 
  na.omit() %>% 
  initial_split(strata = total_weeks)

train <- training(spl)
test <- testing(spl)

set.seed(234)
folds <- vfold_cv(train, strata = total_weeks)
```

```{r}
train %>% 
  count(total_weeks)
```

```{r}
library(textrecipes)

svm_spec <- svm_linear(mode = "classification")

books_rec <- recipe(total_weeks ~ author, data = train) %>% 
  step_tokenize_wordpiece(author, max_chars = 20) %>% 
  step_tokenfilter(author, max_tokens = 100) %>% 
  step_tf(author) %>% 
  step_normalize(all_numeric_predictors())

books_rec %>% 
  prep() %>% 
  bake(new_data = NULL) %>% 
  glimpse()
```

```{r}
books_wf <- workflow(books_rec, svm_spec)
```


```{r}
doParallel::registerDoParallel(cores = 5)

set.seed(123)
books_metrics <- metric_set(accuracy, sens, spec)

books_rs <- books_wf %>% 
  fit_resamples(
    resamples = folds,
    metrics = books_metrics
  )

collect_metrics(books_rs)
```

```{r}
final_rs <- last_fit(books_wf, spl, metrics = books_metrics)

collect_metrics(final_rs)

collect_predictions(final_rs) %>% 
  conf_mat(total_weeks, .pred_class) %>% 
  autoplot()
```

```{r}
fitted_wf <- extract_workflow(final_rs)

augment(fitted_wf, new_data = slice_sample(test, n = 1))
```

```{r}
tidy(fitted_wf) %>% 
  slice_max(abs(estimate), n = 20) %>% 
  mutate(
    term = str_remove(term, "tf_author_"),
    term = fct_reorder(term, abs(estimate))
  ) %>% 
  ggplot(aes(abs(estimate), term, fill = estimate > 0)) +
  geom_col() +
  scale_x_continuous(expand = expansion(0)) +
  scale_fill_discrete(labels = c("Fewer weeks", "More weeks")) +
  labs(x = "Estimate from linear SVM (abslute value)", y = NULL,
       fill = "How many weeks\non best seller list")
```

```{r}
library(vetiver)

v <- vetiver_model(model = fitted_wf, model_name = "nyt_authors")
v

```

```{r}
library(plumber)

pr() %>% 
  vetiver_api(v) %>% 
  pr_run()
```

